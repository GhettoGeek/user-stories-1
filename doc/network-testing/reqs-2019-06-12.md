# Network Testing Framework #

Meeting June 12 2019

Fabio Barone, Rafael Matias, Louis, Vojtech


## Agenda ##

* Swarm Network Testing requirements from different parts of the project. 
  * E.g. Status
  * Incentive MVP and Scaling Swarm in general
* External Partners conversation
* Requirements on testing

 

## Current-Requirements:##

* [Incentives-Track][Fabio] Testing Accounting, doing simulations with running nodes and see if the accounting is working correctly. 

* Simulations are not possible to be run on distributed nodes. [NETWORK LAYER REFLECTION]
  * Only on local nodes we can currently run tests

* [Comm-Track][Louis] 1000 Nodes running distributed having high-volume of messaging
  * With delays, drops and churns
  * Message tracking for debugging?

* CI - Continuous Integration:
  * Different Types of integration tests

 

Simulation Framework: Louis, Fabio and Janosh are informed about that.
 

Rafael: All will require swarm nodes running and talking to each other and test it.
* Check if the functionality is working as expected
* Testing until break it (limitations testing)

 

Current situation:

* Extending the test-framework to create a simulation adapter with an exec-adaptor
* Extend the simulation framework to kybernetik
* Deploy artifact against remote swarm nodes
* Needs to be able to connect to the remote nodes and check for events
* Testsuite - Tests are mixed up together
  * Rafael would like to split up the tests
    * Unit Tests (local)
    * Simulation framework (network-tests)
      * Integration Tests
    * Remote-Notes are even more expensive

 

Resource Demand:
* Louis - increase resource add 1 / 2 ppl


Wish-Outcoming: 
* Pot. epics internal facing + user stories for our next steps 



## Security & Testing: ##
** Basics and guidelines **


- think security in terms of resilience, scalability, stability and availability against attacks, but also against network-failures, user mistakes, outages, fuckups etc

- responsible devs will never allow this: https://twitter.com/yukselisim/status/1105430379132084224

- fail early, fail often - https://medium.com/@davidbrown_70853/fail-early-fail-often-and-fail-forward-58b591f17132

- security (see definition above) MUST be baked-in very early in design-phase and continuously assured via tests, later approaches will be very costly, will increase complexity and slow down

the development-process (elk-test, boeing max-issue)

- never trust userinput

- assume failure everywhere (timestamps, network-disruption during transactions)

- dont be too smart

- simplicity over complexitiy

- never allow a user to shoot themself into the food

- always use sane defaults

- check which metrics are necessary to monitor

- big systems will behave from acertain level very chaotic, you cannot scale endlessly by paper



security-specials


- build up a threat-matrix and where we can or can't/wouldn't address the single issue and how to mitigate

- test and simulations must run on every minor release

- bake attacks and misbehavior into testnet-simulation

- weak network

Latency, drops, churns

- geo-clustering

- all possible fuckups and failures

- chaosmonkey

- chaosbgp

- fuzzing all the things

- big-scale-user-simulation

- replay-attacks

- HUGE scale-simulation to know early on which scaling the network fails, will identify possible bottlenecks and design-problems in early stages

- best practices and documentation

- ALWAYS assume a bad host (misbehaving OR bad actor, it doesnt matter)
